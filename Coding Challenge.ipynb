{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigquery_magics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Will it snow tomorrow?\" - The time traveler asked\n",
    "The following dataset contains climate information from over 9000 stations accross the world. The overall goal of these subtasks will be to predict whether it will snow tomorrow 20 years ago. So if today is 1 April 2025 then the weather we want to forecast is for the 2 April 2005. You are supposed to solve the tasks using Big Query, which can be used in the Jupyter Notebook like it is shown in the following cell. For further information and how to use BigQuery in Jupyter Notebook refer to the Google Docs. \n",
    "\n",
    "The goal of this test is to test your coding knowledge in Python, BigQuery and Pandas as well as your understanding of Data Science. If you get stuck in the first part, you can use the replacement data provided in the second part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.004565000534057617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ec8e5017c24129a06b2b245a85515c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0027916431427001953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 20,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340709ea28d740669324b62f92615e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>wban_number</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>num_mean_temp_samples</th>\n",
       "      <th>mean_dew_point</th>\n",
       "      <th>num_mean_dew_point_samples</th>\n",
       "      <th>mean_sealevel_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>min_temperature_explicit</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>hail</th>\n",
       "      <th>thunder</th>\n",
       "      <th>tornado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39800</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>996.700012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1037.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37770</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>994.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38560</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>36.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>997.799988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>46.700001</td>\n",
       "      <td>4</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1028.099976</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30910</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>983.200012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>53.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>46.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>1010.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39730</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>48.700001</td>\n",
       "      <td>4</td>\n",
       "      <td>1019.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1016.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39530</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1001.099976</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33790</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>46.799999</td>\n",
       "      <td>4</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1007.099976</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38940</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>50.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1008.400024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34970</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>58.799999</td>\n",
       "      <td>5</td>\n",
       "      <td>48.799999</td>\n",
       "      <td>4</td>\n",
       "      <td>1008.900024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>38040</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>996.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34970</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>53.200001</td>\n",
       "      <td>5</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1027.199951</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>38040</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>47.200001</td>\n",
       "      <td>5</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1007.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32620</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>5</td>\n",
       "      <td>34.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>1006.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30750</td>\n",
       "      <td>99999</td>\n",
       "      <td>1930</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>987.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39800</td>\n",
       "      <td>99999</td>\n",
       "      <td>1930</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39730</td>\n",
       "      <td>99999</td>\n",
       "      <td>1930</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>38.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>1016.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_number  wban_number  year  month  day  mean_temp  \\\n",
       "0            39800        99999  1929     11   13  41.299999   \n",
       "1            33110        99999  1929     12   16  45.500000   \n",
       "2            37770        99999  1929     12    8  48.000000   \n",
       "3            38560        99999  1929     11   13  44.500000   \n",
       "4            33110        99999  1929     12   15  46.700001   \n",
       "5            30910        99999  1929     10    6  50.000000   \n",
       "6            33110        99999  1929     10    1  53.299999   \n",
       "7            39730        99999  1929     11    4  54.000000   \n",
       "8            38110        99999  1929     11   18  43.500000   \n",
       "9            39530        99999  1929     10   23  54.000000   \n",
       "10           33790        99999  1929     10   21  46.799999   \n",
       "11           38940        99999  1929     10   19  50.200001   \n",
       "12           34970        99999  1929      8    5  58.799999   \n",
       "13           38040        99999  1929     11   19  54.000000   \n",
       "14           34970        99999  1929     10   13  53.200001   \n",
       "15           38040        99999  1929     12   27  47.200001   \n",
       "16           32620        99999  1929     12   31  38.200001   \n",
       "17           30750        99999  1930     10    6  46.500000   \n",
       "18           39800        99999  1930      7   27  57.500000   \n",
       "19           39730        99999  1930      2   14  43.500000   \n",
       "\n",
       "    num_mean_temp_samples  mean_dew_point  num_mean_dew_point_samples  \\\n",
       "0                       4       37.000000                           4   \n",
       "1                       4       34.500000                           4   \n",
       "2                       4       42.000000                           4   \n",
       "3                       4       36.200001                           4   \n",
       "4                       4       42.500000                           4   \n",
       "5                       4             NaN                        <NA>   \n",
       "6                       4       46.299999                           4   \n",
       "7                       4       48.700001                           4   \n",
       "8                       4       39.500000                           4   \n",
       "9                       4       50.000000                           4   \n",
       "10                      4       42.000000                           4   \n",
       "11                      4       44.000000                           4   \n",
       "12                      5       48.799999                           4   \n",
       "13                      5       53.000000                           4   \n",
       "14                      5       48.500000                           4   \n",
       "15                      5       45.500000                           4   \n",
       "16                      5       34.299999                           4   \n",
       "17                      4       45.500000                           4   \n",
       "18                      4       54.000000                           4   \n",
       "19                      4       38.299999                           4   \n",
       "\n",
       "    mean_sealevel_pressure  ...  min_temperature  min_temperature_explicit  \\\n",
       "0               996.700012  ...              NaN                      <NA>   \n",
       "1              1037.000000  ...              NaN                      <NA>   \n",
       "2               994.500000  ...              NaN                      <NA>   \n",
       "3               997.799988  ...              NaN                      <NA>   \n",
       "4              1028.099976  ...              NaN                      <NA>   \n",
       "5               983.200012  ...              NaN                      <NA>   \n",
       "6              1010.000000  ...              NaN                      <NA>   \n",
       "7              1019.299988  ...              NaN                      <NA>   \n",
       "8              1016.299988  ...              NaN                      <NA>   \n",
       "9              1001.099976  ...              NaN                      <NA>   \n",
       "10             1007.099976  ...              NaN                      <NA>   \n",
       "11             1008.400024  ...              NaN                      <NA>   \n",
       "12             1008.900024  ...              NaN                      <NA>   \n",
       "13              996.299988  ...              NaN                      <NA>   \n",
       "14             1027.199951  ...              NaN                      <NA>   \n",
       "15             1007.500000  ...              NaN                      <NA>   \n",
       "16             1006.500000  ...              NaN                      <NA>   \n",
       "17              987.299988  ...              NaN                      <NA>   \n",
       "18             1005.000000  ...              NaN                      <NA>   \n",
       "19             1016.299988  ...              NaN                      <NA>   \n",
       "\n",
       "    total_precipitation  snow_depth    fog   rain   snow   hail  thunder  \\\n",
       "0                   NaN         NaN  False  False  False  False    False   \n",
       "1                  0.00         NaN  False  False  False  False    False   \n",
       "2                   NaN         NaN  False  False  False  False    False   \n",
       "3                   NaN         NaN  False  False  False  False    False   \n",
       "4                  0.00         NaN  False  False  False  False    False   \n",
       "5                   NaN         NaN  False  False  False  False    False   \n",
       "6                   NaN         NaN  False  False  False  False    False   \n",
       "7                   NaN         NaN  False  False  False  False    False   \n",
       "8                   NaN         NaN  False  False  False  False    False   \n",
       "9                   NaN         NaN  False  False  False  False    False   \n",
       "10                 0.00         NaN  False  False  False  False    False   \n",
       "11                  NaN         NaN  False  False  False  False    False   \n",
       "12                 0.02         NaN  False  False  False  False    False   \n",
       "13                 0.47         NaN  False  False  False  False    False   \n",
       "14                 0.00         NaN  False  False  False  False    False   \n",
       "15                 0.12         NaN  False  False  False  False    False   \n",
       "16                 0.00         NaN  False  False  False  False    False   \n",
       "17                  NaN         NaN  False  False  False  False    False   \n",
       "18                 0.00         NaN  False  False  False  False    False   \n",
       "19                  NaN         NaN  False  False  False  False    False   \n",
       "\n",
       "    tornado  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  \n",
       "5     False  \n",
       "6     False  \n",
       "7     False  \n",
       "8     False  \n",
       "9     False  \n",
       "10    False  \n",
       "11    False  \n",
       "12    False  \n",
       "13    False  \n",
       "14    False  \n",
       "15    False  \n",
       "16    False  \n",
       "17    False  \n",
       "18    False  \n",
       "19    False  \n",
       "\n",
       "[20 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT\n",
    "*,\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "LIMIT 20 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Task\n",
    "Change the date format to 'YYYY-MM-DD' and select the data from 2000 till 2005 for station numbers including and between 725300 and 726300 , and save it as a pandas dataframe. Note the maximum year available is 2010. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.003286600112915039,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46a7a44199944b6ad054d21c9d885eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.002783060073852539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 447037,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10bd969f8c743e4a0866111400945e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%%bigquery df \n",
    "-- save as df pandas dataframe\n",
    "\n",
    "SELECT\n",
    "    FORMAT_DATE('%Y-%m-%d', DATE(year, month, day)) as date, \n",
    "    * EXCEPT(year, month, day) \n",
    "    \n",
    "FROM `bigquery-public-data.samples.gsod` \n",
    "WHERE\n",
    "    year BETWEEN 2000 AND 2005 \n",
    "    AND station_number BETWEEN 725300 AND 726300 \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Task \n",
    "From here you want to work with the data from all stations 725300 to 725330 that have information from 2000 till 2005. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.003396272659301758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75eb40c125a426d84cb9de42815ab83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.003050565719604492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 21853,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b25554b2a5b4a0185a090ec8f35ad16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_number</th>\n",
       "      <th>wban_number</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>num_mean_temp_samples</th>\n",
       "      <th>mean_dew_point</th>\n",
       "      <th>num_mean_dew_point_samples</th>\n",
       "      <th>mean_sealevel_pressure</th>\n",
       "      <th>num_mean_sealevel_pressure_samples</th>\n",
       "      <th>mean_station_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>min_temperature_explicit</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>hail</th>\n",
       "      <th>thunder</th>\n",
       "      <th>tornado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-17</td>\n",
       "      <td>725327</td>\n",
       "      <td>99999</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>21</td>\n",
       "      <td>1028.300049</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-12-06</td>\n",
       "      <td>725326</td>\n",
       "      <td>99999</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>22</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-12</td>\n",
       "      <td>725316</td>\n",
       "      <td>99999</td>\n",
       "      <td>76.800003</td>\n",
       "      <td>23</td>\n",
       "      <td>69.400002</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-08-26</td>\n",
       "      <td>725317</td>\n",
       "      <td>99999</td>\n",
       "      <td>70.300003</td>\n",
       "      <td>23</td>\n",
       "      <td>66.400002</td>\n",
       "      <td>23</td>\n",
       "      <td>1013.200012</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-09-15</td>\n",
       "      <td>725305</td>\n",
       "      <td>99999</td>\n",
       "      <td>55.400002</td>\n",
       "      <td>23</td>\n",
       "      <td>41.799999</td>\n",
       "      <td>23</td>\n",
       "      <td>1019.700012</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21848</th>\n",
       "      <td>2005-04-05</td>\n",
       "      <td>725330</td>\n",
       "      <td>14827</td>\n",
       "      <td>59.900002</td>\n",
       "      <td>24</td>\n",
       "      <td>41.700001</td>\n",
       "      <td>24</td>\n",
       "      <td>1014.799988</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21849</th>\n",
       "      <td>2005-02-04</td>\n",
       "      <td>725300</td>\n",
       "      <td>94846</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>24</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>24</td>\n",
       "      <td>1026.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>1000.799988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21850</th>\n",
       "      <td>2005-02-24</td>\n",
       "      <td>725300</td>\n",
       "      <td>94846</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>24</td>\n",
       "      <td>22.799999</td>\n",
       "      <td>24</td>\n",
       "      <td>1021.799988</td>\n",
       "      <td>24</td>\n",
       "      <td>996.200012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21851</th>\n",
       "      <td>2005-03-28</td>\n",
       "      <td>725327</td>\n",
       "      <td>99999</td>\n",
       "      <td>42.200001</td>\n",
       "      <td>24</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>24</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21852</th>\n",
       "      <td>2005-03-30</td>\n",
       "      <td>725320</td>\n",
       "      <td>14842</td>\n",
       "      <td>62.799999</td>\n",
       "      <td>24</td>\n",
       "      <td>49.599998</td>\n",
       "      <td>24</td>\n",
       "      <td>1000.299988</td>\n",
       "      <td>24</td>\n",
       "      <td>976.400024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21853 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  station_number  wban_number  mean_temp  \\\n",
       "0      2000-03-17          725327        99999  31.000000   \n",
       "1      2000-12-06          725326        99999  13.700000   \n",
       "2      2000-05-12          725316        99999  76.800003   \n",
       "3      2000-08-26          725317        99999  70.300003   \n",
       "4      2000-09-15          725305        99999  55.400002   \n",
       "...           ...             ...          ...        ...   \n",
       "21848  2005-04-05          725330        14827  59.900002   \n",
       "21849  2005-02-04          725300        94846  35.299999   \n",
       "21850  2005-02-24          725300        94846  31.100000   \n",
       "21851  2005-03-28          725327        99999  42.200001   \n",
       "21852  2005-03-30          725320        14842  62.799999   \n",
       "\n",
       "       num_mean_temp_samples  mean_dew_point  num_mean_dew_point_samples  \\\n",
       "0                         21       20.900000                          21   \n",
       "1                         22        2.400000                          22   \n",
       "2                         23       69.400002                          23   \n",
       "3                         23       66.400002                          23   \n",
       "4                         23       41.799999                          23   \n",
       "...                      ...             ...                         ...   \n",
       "21848                     24       41.700001                          24   \n",
       "21849                     24       29.500000                          24   \n",
       "21850                     24       22.799999                          24   \n",
       "21851                     24       30.100000                          24   \n",
       "21852                     24       49.599998                          24   \n",
       "\n",
       "       mean_sealevel_pressure  num_mean_sealevel_pressure_samples  \\\n",
       "0                 1028.300049                                  21   \n",
       "1                         NaN                                <NA>   \n",
       "2                         NaN                                <NA>   \n",
       "3                 1013.200012                                  23   \n",
       "4                 1019.700012                                  21   \n",
       "...                       ...                                 ...   \n",
       "21848             1014.799988                                  24   \n",
       "21849             1026.000000                                  24   \n",
       "21850             1021.799988                                  24   \n",
       "21851             1007.000000                                  24   \n",
       "21852             1000.299988                                  24   \n",
       "\n",
       "       mean_station_pressure  ...  min_temperature  min_temperature_explicit  \\\n",
       "0                        NaN  ...              NaN                      <NA>   \n",
       "1                        NaN  ...              NaN                      <NA>   \n",
       "2                        NaN  ...              NaN                      <NA>   \n",
       "3                        NaN  ...              NaN                      <NA>   \n",
       "4                        NaN  ...              NaN                      <NA>   \n",
       "...                      ...  ...              ...                       ...   \n",
       "21848                    NaN  ...              NaN                      <NA>   \n",
       "21849            1000.799988  ...              NaN                      <NA>   \n",
       "21850             996.200012  ...              NaN                      <NA>   \n",
       "21851                    NaN  ...              NaN                      <NA>   \n",
       "21852             976.400024  ...              NaN                      <NA>   \n",
       "\n",
       "       total_precipitation  snow_depth    fog   rain   snow   hail  thunder  \\\n",
       "0                     0.00         NaN  False  False  False  False    False   \n",
       "1                     0.00         NaN  False  False  False  False    False   \n",
       "2                      NaN         NaN  False  False  False  False    False   \n",
       "3                     0.13         NaN  False  False  False  False    False   \n",
       "4                     0.02         NaN  False  False  False  False    False   \n",
       "...                    ...         ...    ...    ...    ...    ...      ...   \n",
       "21848                 0.00         NaN  False  False  False  False    False   \n",
       "21849                 0.00         1.2   True   True   True   True     True   \n",
       "21850                 0.00         NaN  False  False  False  False    False   \n",
       "21851                 0.00         NaN  False  False  False  False    False   \n",
       "21852                 0.84         NaN   True   True   True   True     True   \n",
       "\n",
       "       tornado  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "...        ...  \n",
       "21848    False  \n",
       "21849     True  \n",
       "21850    False  \n",
       "21851    False  \n",
       "21852     True  \n",
       "\n",
       "[21853 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT\n",
    "    FORMAT_DATE('%Y-%m-%d', DATE(year, month, day)) as date, \n",
    "    * EXCEPT(year, month, day) \n",
    "    \n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "    year BETWEEN 2000 AND 2005 \n",
    "    AND station_number BETWEEN 725300 AND 725330  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by checking which year received the most snowfall in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.003308534622192383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1823ebbc7def4df6b711b9b1bcd070ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0028498172760009766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 6,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2836a5483b44e9b2759951a4e946bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>num_working_station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  num_working_station\n",
       "0  2000                   10\n",
       "1  2001                   10\n",
       "2  2004                   10\n",
       "3  2005                   10\n",
       "4  2002                   10\n",
       "5  2003                   10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "-- We first confirm that in each year the same amount of stations were working\n",
    "SELECT \n",
    "    year,\n",
    "    COUNT(DISTINCT(station_number)) AS num_working_station --count working stations\n",
    "FROM \n",
    "    `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "    year BETWEEN 2000 AND 2005 \n",
    "    AND station_number BETWEEN 725300 AND 725330  \n",
    "GROUP BY\n",
    "    year\n",
    "ORDER BY\n",
    "    num_working_station DESC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0036742687225341797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5cfa291ccb4acdb571903812122e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0029358863830566406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5549a7070b044087a855495d3a0dc07a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>snowy_stations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  snowy_stations\n",
       "0  2005             826"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "-- We count number of stations that have reported snowfall in a year\n",
    "SELECT \n",
    "    year,\n",
    "    COUNT(station_number) AS snowy_stations --count how many stations reported snowfall\n",
    "FROM \n",
    "    `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "    year BETWEEN 2000 AND 2005 \n",
    "    AND station_number BETWEEN 725300 AND 725330  \n",
    "    AND snow = TRUE\n",
    "GROUP BY\n",
    "    year\n",
    "ORDER BY\n",
    "    snowy_stations DESC\n",
    "LIMIT 1 -- show only the year with most snowfall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an additional field that indicates the daily change in snow depth measured at every station. And identify the station and day for which the snow depth increased the most.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0031604766845703125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15dac7ceb64a452fa894bd8ab22d56d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.003175497055053711,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c539b4707751481a8fc3be34a6ab47ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_number</th>\n",
       "      <th>snow_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-22</td>\n",
       "      <td>725300</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  station_number  snow_diff\n",
       "0  2005-01-22          725300        9.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%bigquery \n",
    "\n",
    "SELECT\n",
    "    FORMAT_DATE('%Y-%m-%d', DATE(year, month, day)) AS date, \n",
    "    station_number,\n",
    "    snow_depth - LAG(snow_depth) OVER (\n",
    "      PARTITION BY station_number \n",
    "      ORDER BY DATE(year, month, day)\n",
    "    ) AS snow_diff -- Compute difference between current and previous snow depth\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "    year BETWEEN 2000 AND 2005 AND \n",
    "    station_number BETWEEN 725300 AND 725330 \n",
    "ORDER BY snow_diff DESC -- Highest diff first\n",
    "LIMIT 1 -- Show only the first row with highest snow change increase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do further checks on the remaining dataset, clean or drop data depending on how you see appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0031037330627441406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51da89d0e8ba4bf6bee967b2a257e08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0029077529907226562,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 21853,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435b3fc41a2244bc9b310e0e9651a854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery df\n",
    "-- Again save the data needed in further tasks\n",
    "SELECT\n",
    "    FORMAT_DATE('%Y-%m-%d', DATE(year, month, day)) AS date,\n",
    "    * EXCEPT (year, month, day)\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "    year BETWEEN 2000 AND 2005 AND\n",
    "    station_number BETWEEN 725300 AND 725330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "df_copy = df.copy() # Copy dataframe\n",
    "\n",
    "df_copy['date'] = pd.to_datetime(df_copy['date'])\n",
    "df_copy = df_copy.sort_values(by=['station_number', 'date']) # Sort by date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                          0\n",
      "station_number                0\n",
      "mean_temp                     0\n",
      "mean_dew_point                7\n",
      "mean_visibility              16\n",
      "mean_wind_speed               7\n",
      "max_sustained_wind_speed      8\n",
      "max_temperature               1\n",
      "max_temperature_explicit      1\n",
      "total_precipitation         296\n",
      "fog                           0\n",
      "rain                          0\n",
      "snow                          0\n",
      "hail                          0\n",
      "thunder                       0\n",
      "tornado                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "df_clean_tmp = df_copy.drop(['wban_number', 'num_mean_temp_samples', 'num_mean_dew_point_samples', 'num_mean_sealevel_pressure_samples', 'num_mean_visibility_samples', 'num_mean_wind_speed_samples'], axis=1) # Drop columns which are unnecessary for snowfall prediction\n",
    "df_clean_tmp = df_clean_tmp.drop(['mean_sealevel_pressure', 'mean_station_pressure', 'num_mean_station_pressure_samples', 'min_temperature', 'min_temperature_explicit', 'snow_depth', 'max_gust_wind_speed'], axis=1) # Drop columns with too many NaN's\n",
    "print(df_clean_tmp.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                          0\n",
      "station_number                0\n",
      "mean_temp                     0\n",
      "mean_dew_point                0\n",
      "mean_visibility               0\n",
      "mean_wind_speed               0\n",
      "max_sustained_wind_speed      8\n",
      "max_temperature               0\n",
      "max_temperature_explicit      0\n",
      "total_precipitation         296\n",
      "fog                           0\n",
      "rain                          0\n",
      "snow                          0\n",
      "hail                          0\n",
      "thunder                       0\n",
      "tornado                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill in NaN values with values from previous dates\n",
    "df_clean_tmp['mean_dew_point'] = df_clean_tmp.groupby('station_number')['mean_dew_point'].ffill()\n",
    "df_clean_tmp['mean_visibility'] = df_clean_tmp.groupby('station_number')['mean_visibility'].ffill()\n",
    "df_clean_tmp['mean_wind_speed'] = df_clean_tmp.groupby('station_number')['mean_wind_speed'].ffill()\n",
    "df_clean_tmp['max_temperature'] = df_clean_tmp.groupby('station_number')['max_temperature'].ffill()\n",
    "df_clean_tmp['max_temperature_explicit'] = df_clean_tmp.groupby('station_number')['max_temperature_explicit'].ffill()\n",
    "print(df_clean_tmp.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average 6.237495956865103\n",
      "date                          0\n",
      "station_number                0\n",
      "mean_temp                     0\n",
      "mean_dew_point                0\n",
      "mean_visibility               0\n",
      "mean_wind_speed               0\n",
      "max_sustained_wind_speed      0\n",
      "max_temperature               0\n",
      "max_temperature_explicit      0\n",
      "total_precipitation         296\n",
      "fog                           0\n",
      "rain                          0\n",
      "snow                          0\n",
      "hail                          0\n",
      "thunder                       0\n",
      "tornado                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Compute average difference betwee mean wind speed and max sustained wind speed & and fill in NaN\n",
    "df_wind = df_clean_tmp[['max_sustained_wind_speed', 'mean_wind_speed']].dropna() # Remove NaN from avrage comp.\n",
    "df_wind_diff = df_wind['max_sustained_wind_speed'] - df_wind['mean_wind_speed']\n",
    "df_wind_diff = np.array(df_wind_diff.to_list())\n",
    "average = np.mean(df_wind_diff)\n",
    "print(f\"average {average}\")\n",
    "df_clean_tmp['max_sustained_wind_speed'] = df_clean_tmp['max_sustained_wind_speed'].fillna(df_clean_tmp['mean_wind_speed'] + average) # Fill in NaN by max wind speed + average\n",
    "print(df_clean_tmp.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                        0\n",
      "station_number              0\n",
      "mean_temp                   0\n",
      "mean_dew_point              0\n",
      "mean_visibility             0\n",
      "mean_wind_speed             0\n",
      "max_sustained_wind_speed    0\n",
      "max_temperature             0\n",
      "max_temperature_explicit    0\n",
      "total_precipitation         0\n",
      "fog                         0\n",
      "rain                        0\n",
      "snow                        0\n",
      "hail                        0\n",
      "thunder                     0\n",
      "tornado                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill in NaN with 0.0 for total precipitation if there was no rain, snow and hail on given day\n",
    "df_clean_tmp['total_precipitation'] = df_clean_tmp.apply(\n",
    "    lambda row: 0.0 if pd.isna(row['total_precipitation']) and not row['rain'] and not row['snow'] and not row['hail'] else row['total_precipitation'],\n",
    "    axis=1\n",
    ")\n",
    "df_clean_tmp['total_precipitation'] = df_clean_tmp.groupby('station_number')['total_precipitation'].ffill() # Fill the reamining with values from prev. days\n",
    "print(df_clean_tmp.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                        datetime64[ns]\n",
       "station_number                       Int64\n",
       "mean_temp                          float64\n",
       "mean_dew_point                     float64\n",
       "mean_visibility                    float64\n",
       "mean_wind_speed                    float64\n",
       "max_sustained_wind_speed           float64\n",
       "max_temperature                    float64\n",
       "max_temperature_explicit           boolean\n",
       "total_precipitation                float64\n",
       "fog                                boolean\n",
       "rain                               boolean\n",
       "snow                               boolean\n",
       "hail                               boolean\n",
       "thunder                            boolean\n",
       "tornado                            boolean\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_tmp.dtypes # Check if data types match categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_tmp['day_diff'] = (df_clean_tmp.groupby('station_number')['date'].shift(-1) - df_clean_tmp['date']).dt.days # Compute the difference in days between neighbouring rows\n",
    "df_clean_tmp['target'] = df_clean_tmp.groupby('station_number')['snow'].shift(-1) # Create new target column containing information about snow from the next day\n",
    "\n",
    "# Add data from day before \n",
    "df_clean_tmp['snow_before'] = df_clean_tmp.groupby('station_number')['snow'].shift(1) \n",
    "df_clean_tmp['rain_before'] = df_clean_tmp.groupby('station_number')['rain'].shift(1)\n",
    "df_clean_tmp['mean_temp_before'] = df_clean_tmp.groupby('station_number')['mean_temp'].shift(1)\n",
    "df_clean_tmp['total_precipitation_before'] = df_clean_tmp.groupby('station_number')['total_precipitation'].shift(1)\n",
    "df_clean_tmp['mean_dew_point_before'] = df_clean_tmp.groupby('station_number')['mean_dew_point'].shift(1)\n",
    "df_clean_tmp['max_temperature_before'] = df_clean_tmp.groupby('station_number')['max_temperature'].shift(1)\n",
    "\n",
    "df_clean_tmp = df_clean_tmp[df_clean_tmp['day_diff'] == 1] # Remove data where the next day is missing\n",
    "df_clean_tmp = df_clean_tmp.dropna() # Drop NA values resulting from injecting data from previous/next days\n",
    "\n",
    "# Convert bool. columns into binary 0 and 1\n",
    "bool_cols = df_clean_tmp.select_dtypes(include='bool').columns \n",
    "df_clean_tmp[bool_cols] = df_clean_tmp[bool_cols].astype(int)\n",
    "\n",
    "\n",
    "df_clean = df_clean_tmp.copy()\n",
    "assert not df_clean.isnull().values.any(), \"DataFrame contains NaN values\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Task\n",
    "Now it is time to split the data, into a training, evaluation and test set. As a reminder, the date we are trying to predict snow fall for should constitute your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall length 21795\n",
      "Train set length 18183\n",
      "Evaluation set length 3602\n",
      "Test set length 10\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "date_to_predict = str(dt.datetime.today()- dt.timedelta(days=20*365)).split(' ')[0]\n",
    "\n",
    "# Train set contains data from 2000 until 2004\n",
    "train_df = df_clean[df_clean['date'] <= '2004-12-31']\n",
    "\n",
    "# Evaluation set contains data from 2004 until 2005 except for \"date_to_predict\"\n",
    "eval_df = df_clean[(df_clean['date'] > '2004-12-31') & (df_clean['date'] != date_to_predict)]\n",
    "\n",
    "# Test set contains data with the same date as \"date_to_predict\"\n",
    "test_df = df_clean[(df_clean['date'] == date_to_predict)]\n",
    "\n",
    "print(f\"Overall length {len(df_clean)}\")\n",
    "print(f\"Train set length {len(train_df)}\")\n",
    "print(f\"Evaluation set length {len(eval_df)}\")\n",
    "print(f\"Test set length {len(test_df)}\")\n",
    "\n",
    "assert len(df_clean) == len(train_df) + len(eval_df) + len(test_df), \"The lengths of the train, evaluation, and test sets do not sum to the length of the whole dataset\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "If you made it up to here all by yourself, you can use your prepared dataset to train an algorithm of your choice to forecast whether it will snow on the following date for each station in this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2005-05-11'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "str(dt.datetime.today()- dt.timedelta(days=20*365)).split(' ')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are allowed to use any library you are comfortable with such as sklearn, tensorflow, keras etc. \n",
    "If you did not manage to finish part one feel free to use the data provided in 'coding_challenge.csv' Note that this data does not represent a solution to Part 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "7l_datascience",
   "language": "python",
   "name": "7l_datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
