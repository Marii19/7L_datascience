{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigquery_magics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Will it snow tomorrow?\" - The time traveler asked\n",
    "The following dataset contains climate information from over 9000 stations accross the world. The overall goal of these subtasks will be to predict whether it will snow tomorrow 20 years ago. So if today is 1 April 2025 then the weather we want to forecast is for the 2 April 2005. You are supposed to solve the tasks using Big Query, which can be used in the Jupyter Notebook like it is shown in the following cell. For further information and how to use BigQuery in Jupyter Notebook refer to the Google Docs. \n",
    "\n",
    "The goal of this test is to test your coding knowledge in Python, BigQuery and Pandas as well as your understanding of Data Science. If you get stuck in the first part, you can use the replacement data provided in the second part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.004076242446899414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57017f1fa44e4a73a030af84dd40c09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.002499818801879883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 20,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90388cd5802a45388bfc8d1ad6c7c30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>wban_number</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>num_mean_temp_samples</th>\n",
       "      <th>mean_dew_point</th>\n",
       "      <th>num_mean_dew_point_samples</th>\n",
       "      <th>mean_sealevel_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>min_temperature_explicit</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>hail</th>\n",
       "      <th>thunder</th>\n",
       "      <th>tornado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39800</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>996.700012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1037.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37770</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>994.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38560</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>36.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>997.799988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>46.700001</td>\n",
       "      <td>4</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1028.099976</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30910</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>983.200012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>53.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>46.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>1010.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39730</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>48.700001</td>\n",
       "      <td>4</td>\n",
       "      <td>1019.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1016.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39530</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1001.099976</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33790</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>46.799999</td>\n",
       "      <td>4</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1007.099976</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38940</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>50.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1008.400024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34970</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>58.799999</td>\n",
       "      <td>5</td>\n",
       "      <td>48.799999</td>\n",
       "      <td>4</td>\n",
       "      <td>1008.900024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>38040</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>996.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34970</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>53.200001</td>\n",
       "      <td>5</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1027.199951</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>38040</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>47.200001</td>\n",
       "      <td>5</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1007.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32620</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>5</td>\n",
       "      <td>34.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>1006.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30750</td>\n",
       "      <td>99999</td>\n",
       "      <td>1930</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>987.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39800</td>\n",
       "      <td>99999</td>\n",
       "      <td>1930</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39730</td>\n",
       "      <td>99999</td>\n",
       "      <td>1930</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>38.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>1016.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_number  wban_number  year  month  day  mean_temp  \\\n",
       "0            39800        99999  1929     11   13  41.299999   \n",
       "1            33110        99999  1929     12   16  45.500000   \n",
       "2            37770        99999  1929     12    8  48.000000   \n",
       "3            38560        99999  1929     11   13  44.500000   \n",
       "4            33110        99999  1929     12   15  46.700001   \n",
       "5            30910        99999  1929     10    6  50.000000   \n",
       "6            33110        99999  1929     10    1  53.299999   \n",
       "7            39730        99999  1929     11    4  54.000000   \n",
       "8            38110        99999  1929     11   18  43.500000   \n",
       "9            39530        99999  1929     10   23  54.000000   \n",
       "10           33790        99999  1929     10   21  46.799999   \n",
       "11           38940        99999  1929     10   19  50.200001   \n",
       "12           34970        99999  1929      8    5  58.799999   \n",
       "13           38040        99999  1929     11   19  54.000000   \n",
       "14           34970        99999  1929     10   13  53.200001   \n",
       "15           38040        99999  1929     12   27  47.200001   \n",
       "16           32620        99999  1929     12   31  38.200001   \n",
       "17           30750        99999  1930     10    6  46.500000   \n",
       "18           39800        99999  1930      7   27  57.500000   \n",
       "19           39730        99999  1930      2   14  43.500000   \n",
       "\n",
       "    num_mean_temp_samples  mean_dew_point  num_mean_dew_point_samples  \\\n",
       "0                       4       37.000000                           4   \n",
       "1                       4       34.500000                           4   \n",
       "2                       4       42.000000                           4   \n",
       "3                       4       36.200001                           4   \n",
       "4                       4       42.500000                           4   \n",
       "5                       4             NaN                        <NA>   \n",
       "6                       4       46.299999                           4   \n",
       "7                       4       48.700001                           4   \n",
       "8                       4       39.500000                           4   \n",
       "9                       4       50.000000                           4   \n",
       "10                      4       42.000000                           4   \n",
       "11                      4       44.000000                           4   \n",
       "12                      5       48.799999                           4   \n",
       "13                      5       53.000000                           4   \n",
       "14                      5       48.500000                           4   \n",
       "15                      5       45.500000                           4   \n",
       "16                      5       34.299999                           4   \n",
       "17                      4       45.500000                           4   \n",
       "18                      4       54.000000                           4   \n",
       "19                      4       38.299999                           4   \n",
       "\n",
       "    mean_sealevel_pressure  ...  min_temperature  min_temperature_explicit  \\\n",
       "0               996.700012  ...              NaN                      <NA>   \n",
       "1              1037.000000  ...              NaN                      <NA>   \n",
       "2               994.500000  ...              NaN                      <NA>   \n",
       "3               997.799988  ...              NaN                      <NA>   \n",
       "4              1028.099976  ...              NaN                      <NA>   \n",
       "5               983.200012  ...              NaN                      <NA>   \n",
       "6              1010.000000  ...              NaN                      <NA>   \n",
       "7              1019.299988  ...              NaN                      <NA>   \n",
       "8              1016.299988  ...              NaN                      <NA>   \n",
       "9              1001.099976  ...              NaN                      <NA>   \n",
       "10             1007.099976  ...              NaN                      <NA>   \n",
       "11             1008.400024  ...              NaN                      <NA>   \n",
       "12             1008.900024  ...              NaN                      <NA>   \n",
       "13              996.299988  ...              NaN                      <NA>   \n",
       "14             1027.199951  ...              NaN                      <NA>   \n",
       "15             1007.500000  ...              NaN                      <NA>   \n",
       "16             1006.500000  ...              NaN                      <NA>   \n",
       "17              987.299988  ...              NaN                      <NA>   \n",
       "18             1005.000000  ...              NaN                      <NA>   \n",
       "19             1016.299988  ...              NaN                      <NA>   \n",
       "\n",
       "    total_precipitation  snow_depth    fog   rain   snow   hail  thunder  \\\n",
       "0                   NaN         NaN  False  False  False  False    False   \n",
       "1                  0.00         NaN  False  False  False  False    False   \n",
       "2                   NaN         NaN  False  False  False  False    False   \n",
       "3                   NaN         NaN  False  False  False  False    False   \n",
       "4                  0.00         NaN  False  False  False  False    False   \n",
       "5                   NaN         NaN  False  False  False  False    False   \n",
       "6                   NaN         NaN  False  False  False  False    False   \n",
       "7                   NaN         NaN  False  False  False  False    False   \n",
       "8                   NaN         NaN  False  False  False  False    False   \n",
       "9                   NaN         NaN  False  False  False  False    False   \n",
       "10                 0.00         NaN  False  False  False  False    False   \n",
       "11                  NaN         NaN  False  False  False  False    False   \n",
       "12                 0.02         NaN  False  False  False  False    False   \n",
       "13                 0.47         NaN  False  False  False  False    False   \n",
       "14                 0.00         NaN  False  False  False  False    False   \n",
       "15                 0.12         NaN  False  False  False  False    False   \n",
       "16                 0.00         NaN  False  False  False  False    False   \n",
       "17                  NaN         NaN  False  False  False  False    False   \n",
       "18                 0.00         NaN  False  False  False  False    False   \n",
       "19                  NaN         NaN  False  False  False  False    False   \n",
       "\n",
       "    tornado  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  \n",
       "5     False  \n",
       "6     False  \n",
       "7     False  \n",
       "8     False  \n",
       "9     False  \n",
       "10    False  \n",
       "11    False  \n",
       "12    False  \n",
       "13    False  \n",
       "14    False  \n",
       "15    False  \n",
       "16    False  \n",
       "17    False  \n",
       "18    False  \n",
       "19    False  \n",
       "\n",
       "[20 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT\n",
    "*,\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "LIMIT 20 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Task\n",
    "Change the date format to 'YYYY-MM-DD' and select the data from 2000 till 2005 for station numbers including and between 725300 and 726300 , and save it as a pandas dataframe. Note the maximum year available is 2010. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0035173892974853516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ff5557bc7a4c898e08d2f598756fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.004007101058959961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 447037,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d3d77bc6fe4d66b07c2719f7b68b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%%bigquery df \n",
    "-- save as df pandas dataframe\n",
    "\n",
    "SELECT\n",
    "    FORMAT_DATE('%Y-%m-%d', DATE(year, month, day)) as date, \n",
    "    * EXCEPT(year, month, day) \n",
    "    \n",
    "FROM `bigquery-public-data.samples.gsod` \n",
    "WHERE\n",
    "    year BETWEEN 2000 AND 2005 \n",
    "    AND station_number BETWEEN 725300 AND 726300 \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Task \n",
    "From here you want to work with the data from all stations 725300 to 725330 that have information from 2000 till 2005. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0032541751861572266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348f9372696c4f7eadb14f1c44b6d8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.003737211227416992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 21853,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42def18cdb2b46d8aa77eae1a7fb7616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_number</th>\n",
       "      <th>wban_number</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>num_mean_temp_samples</th>\n",
       "      <th>mean_dew_point</th>\n",
       "      <th>num_mean_dew_point_samples</th>\n",
       "      <th>mean_sealevel_pressure</th>\n",
       "      <th>num_mean_sealevel_pressure_samples</th>\n",
       "      <th>mean_station_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>min_temperature_explicit</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>hail</th>\n",
       "      <th>thunder</th>\n",
       "      <th>tornado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-17</td>\n",
       "      <td>725327</td>\n",
       "      <td>99999</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>21</td>\n",
       "      <td>1028.300049</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-12-06</td>\n",
       "      <td>725326</td>\n",
       "      <td>99999</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>22</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-12</td>\n",
       "      <td>725316</td>\n",
       "      <td>99999</td>\n",
       "      <td>76.800003</td>\n",
       "      <td>23</td>\n",
       "      <td>69.400002</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-08-26</td>\n",
       "      <td>725317</td>\n",
       "      <td>99999</td>\n",
       "      <td>70.300003</td>\n",
       "      <td>23</td>\n",
       "      <td>66.400002</td>\n",
       "      <td>23</td>\n",
       "      <td>1013.200012</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-09-15</td>\n",
       "      <td>725305</td>\n",
       "      <td>99999</td>\n",
       "      <td>55.400002</td>\n",
       "      <td>23</td>\n",
       "      <td>41.799999</td>\n",
       "      <td>23</td>\n",
       "      <td>1019.700012</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21848</th>\n",
       "      <td>2005-04-05</td>\n",
       "      <td>725330</td>\n",
       "      <td>14827</td>\n",
       "      <td>59.900002</td>\n",
       "      <td>24</td>\n",
       "      <td>41.700001</td>\n",
       "      <td>24</td>\n",
       "      <td>1014.799988</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21849</th>\n",
       "      <td>2005-02-04</td>\n",
       "      <td>725300</td>\n",
       "      <td>94846</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>24</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>24</td>\n",
       "      <td>1026.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>1000.799988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21850</th>\n",
       "      <td>2005-02-24</td>\n",
       "      <td>725300</td>\n",
       "      <td>94846</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>24</td>\n",
       "      <td>22.799999</td>\n",
       "      <td>24</td>\n",
       "      <td>1021.799988</td>\n",
       "      <td>24</td>\n",
       "      <td>996.200012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21851</th>\n",
       "      <td>2005-03-28</td>\n",
       "      <td>725327</td>\n",
       "      <td>99999</td>\n",
       "      <td>42.200001</td>\n",
       "      <td>24</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>24</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21852</th>\n",
       "      <td>2005-03-30</td>\n",
       "      <td>725320</td>\n",
       "      <td>14842</td>\n",
       "      <td>62.799999</td>\n",
       "      <td>24</td>\n",
       "      <td>49.599998</td>\n",
       "      <td>24</td>\n",
       "      <td>1000.299988</td>\n",
       "      <td>24</td>\n",
       "      <td>976.400024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21853 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  station_number  wban_number  mean_temp  \\\n",
       "0      2000-03-17          725327        99999  31.000000   \n",
       "1      2000-12-06          725326        99999  13.700000   \n",
       "2      2000-05-12          725316        99999  76.800003   \n",
       "3      2000-08-26          725317        99999  70.300003   \n",
       "4      2000-09-15          725305        99999  55.400002   \n",
       "...           ...             ...          ...        ...   \n",
       "21848  2005-04-05          725330        14827  59.900002   \n",
       "21849  2005-02-04          725300        94846  35.299999   \n",
       "21850  2005-02-24          725300        94846  31.100000   \n",
       "21851  2005-03-28          725327        99999  42.200001   \n",
       "21852  2005-03-30          725320        14842  62.799999   \n",
       "\n",
       "       num_mean_temp_samples  mean_dew_point  num_mean_dew_point_samples  \\\n",
       "0                         21       20.900000                          21   \n",
       "1                         22        2.400000                          22   \n",
       "2                         23       69.400002                          23   \n",
       "3                         23       66.400002                          23   \n",
       "4                         23       41.799999                          23   \n",
       "...                      ...             ...                         ...   \n",
       "21848                     24       41.700001                          24   \n",
       "21849                     24       29.500000                          24   \n",
       "21850                     24       22.799999                          24   \n",
       "21851                     24       30.100000                          24   \n",
       "21852                     24       49.599998                          24   \n",
       "\n",
       "       mean_sealevel_pressure  num_mean_sealevel_pressure_samples  \\\n",
       "0                 1028.300049                                  21   \n",
       "1                         NaN                                <NA>   \n",
       "2                         NaN                                <NA>   \n",
       "3                 1013.200012                                  23   \n",
       "4                 1019.700012                                  21   \n",
       "...                       ...                                 ...   \n",
       "21848             1014.799988                                  24   \n",
       "21849             1026.000000                                  24   \n",
       "21850             1021.799988                                  24   \n",
       "21851             1007.000000                                  24   \n",
       "21852             1000.299988                                  24   \n",
       "\n",
       "       mean_station_pressure  ...  min_temperature  min_temperature_explicit  \\\n",
       "0                        NaN  ...              NaN                      <NA>   \n",
       "1                        NaN  ...              NaN                      <NA>   \n",
       "2                        NaN  ...              NaN                      <NA>   \n",
       "3                        NaN  ...              NaN                      <NA>   \n",
       "4                        NaN  ...              NaN                      <NA>   \n",
       "...                      ...  ...              ...                       ...   \n",
       "21848                    NaN  ...              NaN                      <NA>   \n",
       "21849            1000.799988  ...              NaN                      <NA>   \n",
       "21850             996.200012  ...              NaN                      <NA>   \n",
       "21851                    NaN  ...              NaN                      <NA>   \n",
       "21852             976.400024  ...              NaN                      <NA>   \n",
       "\n",
       "       total_precipitation  snow_depth    fog   rain   snow   hail  thunder  \\\n",
       "0                     0.00         NaN  False  False  False  False    False   \n",
       "1                     0.00         NaN  False  False  False  False    False   \n",
       "2                      NaN         NaN  False  False  False  False    False   \n",
       "3                     0.13         NaN  False  False  False  False    False   \n",
       "4                     0.02         NaN  False  False  False  False    False   \n",
       "...                    ...         ...    ...    ...    ...    ...      ...   \n",
       "21848                 0.00         NaN  False  False  False  False    False   \n",
       "21849                 0.00         1.2   True   True   True   True     True   \n",
       "21850                 0.00         NaN  False  False  False  False    False   \n",
       "21851                 0.00         NaN  False  False  False  False    False   \n",
       "21852                 0.84         NaN   True   True   True   True     True   \n",
       "\n",
       "       tornado  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "...        ...  \n",
       "21848    False  \n",
       "21849     True  \n",
       "21850    False  \n",
       "21851    False  \n",
       "21852     True  \n",
       "\n",
       "[21853 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT\n",
    "    FORMAT_DATE('%Y-%m-%d', DATE(year, month, day)) as date, \n",
    "    * EXCEPT(year, month, day) \n",
    "    \n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "    year BETWEEN 2000 AND 2005 \n",
    "    AND station_number BETWEEN 725300 AND 725330  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by checking which year received the most snowfall in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0034608840942382812,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0ceaba0c93476987734913851b6eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0029027462005615234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 6,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f8944754d44366bdf2f60ce77b0838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>num_working_station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  num_working_station\n",
       "0  2000                   10\n",
       "1  2001                   10\n",
       "2  2004                   10\n",
       "3  2005                   10\n",
       "4  2002                   10\n",
       "5  2003                   10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "-- We first confirm that in each year the same amount of stations were working\n",
    "SELECT \n",
    "    year,\n",
    "    COUNT(DISTINCT(station_number)) AS num_working_station --count working stations\n",
    "FROM \n",
    "    `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "    year BETWEEN 2000 AND 2005 \n",
    "    AND station_number BETWEEN 725300 AND 725330  \n",
    "GROUP BY\n",
    "    year\n",
    "ORDER BY\n",
    "    num_working_station DESC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.003342151641845703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60da8fe2f36745a288fab2a7fa09c901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0028123855590820312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e41c5f1fc34a2e81f317c7285d3ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>snowy_stations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  snowy_stations\n",
       "0  2005             826"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "-- We count number of stations that have reported snowfall in a year\n",
    "SELECT \n",
    "    year,\n",
    "    COUNT(station_number) AS snowy_stations --count how many stations reported snowfall\n",
    "FROM \n",
    "    `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "    year BETWEEN 2000 AND 2005 \n",
    "    AND station_number BETWEEN 725300 AND 725330  \n",
    "    AND snow = TRUE\n",
    "GROUP BY\n",
    "    year\n",
    "ORDER BY\n",
    "    snowy_stations DESC\n",
    "LIMIT 1 -- show only the year with most snowfall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an additional field that indicates the daily change in snow depth measured at every station. And identify the station and day for which the snow depth increased the most.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.003449678421020508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77e38e9c3fd4b5b846ed6365ef665c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0031349658966064453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddd75fbcd8943d1a444f87932322fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_number</th>\n",
       "      <th>snow_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-22</td>\n",
       "      <td>725300</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  station_number  snow_diff\n",
       "0  2005-01-22          725300        9.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%bigquery \n",
    "\n",
    "SELECT\n",
    "    FORMAT_DATE('%Y-%m-%d', DATE(year, month, day)) AS date, \n",
    "    station_number,\n",
    "    snow_depth - LAG(snow_depth) OVER (\n",
    "      PARTITION BY station_number \n",
    "      ORDER BY DATE(year, month, day)\n",
    "    ) AS snow_diff -- Compute difference between current and previous snow depth\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "    year BETWEEN 2000 AND 2005 AND \n",
    "    station_number BETWEEN 725300 AND 725330 \n",
    "ORDER BY snow_diff DESC -- Highest diff first\n",
    "LIMIT 1 -- Show only the first row with highest snow change increase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do further checks on the remaining dataset, clean or drop data depending on how you see appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.003753185272216797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Query is running",
       "rate": null,
       "total": 1,
       "unit": "query",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f06ac82c6f49e4b48c2ed1e516dcd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}|",
       "colour": null,
       "elapsed": 0.0032126903533935547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 21853,
       "unit": "rows",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87504090c5e48019f0d9d5e58212f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery df\n",
    "-- Again save the data needed in further tasks\n",
    "SELECT\n",
    "    FORMAT_DATE('%Y-%m-%d', DATE(year, month, day)) AS date,\n",
    "    * EXCEPT (year, month, day)\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "    year BETWEEN 2000 AND 2005 AND\n",
    "    station_number BETWEEN 725300 AND 725330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "df_copy = df.copy() # Copy dataframe\n",
    "\n",
    "df_copy['date'] = pd.to_datetime(df_copy['date'])\n",
    "df_copy = df_copy.sort_values(by=['station_number', 'date']) # Sort by date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                          0\n",
      "station_number                0\n",
      "mean_temp                     0\n",
      "mean_dew_point                7\n",
      "mean_visibility              16\n",
      "mean_wind_speed               7\n",
      "max_sustained_wind_speed      8\n",
      "max_temperature               1\n",
      "max_temperature_explicit      1\n",
      "total_precipitation         296\n",
      "fog                           0\n",
      "rain                          0\n",
      "snow                          0\n",
      "hail                          0\n",
      "thunder                       0\n",
      "tornado                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "df_clean_tmp = df_copy.drop(['wban_number', 'num_mean_temp_samples', 'num_mean_dew_point_samples', 'num_mean_sealevel_pressure_samples', 'num_mean_visibility_samples', 'num_mean_wind_speed_samples'], axis=1) # Drop columns which are unnecessary for snowfall prediction\n",
    "df_clean_tmp = df_clean_tmp.drop(['mean_sealevel_pressure', 'mean_station_pressure', 'num_mean_station_pressure_samples', 'min_temperature', 'min_temperature_explicit', 'snow_depth', 'max_gust_wind_speed'], axis=1) # Drop columns with too many NaN's\n",
    "print(df_clean_tmp.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                          0\n",
      "station_number                0\n",
      "mean_temp                     0\n",
      "mean_dew_point                0\n",
      "mean_visibility               0\n",
      "mean_wind_speed               0\n",
      "max_sustained_wind_speed      8\n",
      "max_temperature               0\n",
      "max_temperature_explicit      0\n",
      "total_precipitation         296\n",
      "fog                           0\n",
      "rain                          0\n",
      "snow                          0\n",
      "hail                          0\n",
      "thunder                       0\n",
      "tornado                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill in NaN values with values from previous dates\n",
    "df_clean_tmp['mean_dew_point'] = df_clean_tmp.groupby('station_number')['mean_dew_point'].ffill()\n",
    "df_clean_tmp['mean_visibility'] = df_clean_tmp.groupby('station_number')['mean_visibility'].ffill()\n",
    "df_clean_tmp['mean_wind_speed'] = df_clean_tmp.groupby('station_number')['mean_wind_speed'].ffill()\n",
    "df_clean_tmp['max_temperature'] = df_clean_tmp.groupby('station_number')['max_temperature'].ffill()\n",
    "df_clean_tmp['max_temperature_explicit'] = df_clean_tmp.groupby('station_number')['max_temperature_explicit'].ffill()\n",
    "print(df_clean_tmp.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average 6.237495956865103\n",
      "date                          0\n",
      "station_number                0\n",
      "mean_temp                     0\n",
      "mean_dew_point                0\n",
      "mean_visibility               0\n",
      "mean_wind_speed               0\n",
      "max_sustained_wind_speed      0\n",
      "max_temperature               0\n",
      "max_temperature_explicit      0\n",
      "total_precipitation         296\n",
      "fog                           0\n",
      "rain                          0\n",
      "snow                          0\n",
      "hail                          0\n",
      "thunder                       0\n",
      "tornado                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Compute average difference betwee mean wind speed and max sustained wind speed & and fill in NaN\n",
    "df_wind = df_clean_tmp[['max_sustained_wind_speed', 'mean_wind_speed']].dropna() # Remove NaN from avrage comp.\n",
    "df_wind_diff = df_wind['max_sustained_wind_speed'] - df_wind['mean_wind_speed']\n",
    "df_wind_diff = np.array(df_wind_diff.to_list())\n",
    "average = np.mean(df_wind_diff)\n",
    "print(f\"average {average}\")\n",
    "df_clean_tmp['max_sustained_wind_speed'] = df_clean_tmp['max_sustained_wind_speed'].fillna(df_clean_tmp['mean_wind_speed'] + average) # Fill in NaN by max wind speed + average\n",
    "print(df_clean_tmp.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                        0\n",
      "station_number              0\n",
      "mean_temp                   0\n",
      "mean_dew_point              0\n",
      "mean_visibility             0\n",
      "mean_wind_speed             0\n",
      "max_sustained_wind_speed    0\n",
      "max_temperature             0\n",
      "max_temperature_explicit    0\n",
      "total_precipitation         0\n",
      "fog                         0\n",
      "rain                        0\n",
      "snow                        0\n",
      "hail                        0\n",
      "thunder                     0\n",
      "tornado                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill in NaN with 0.0 for total precipitation if there was no rain, snow and hail on given day\n",
    "df_clean_tmp['total_precipitation'] = df_clean_tmp.apply(\n",
    "    lambda row: 0.0 if pd.isna(row['total_precipitation']) and not row['rain'] and not row['snow'] and not row['hail'] else row['total_precipitation'],\n",
    "    axis=1\n",
    ")\n",
    "df_clean_tmp['total_precipitation'] = df_clean_tmp.groupby('station_number')['total_precipitation'].ffill() # Fill the reamining with values from prev. days\n",
    "print(df_clean_tmp.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                        datetime64[ns]\n",
       "station_number                       Int64\n",
       "mean_temp                          float64\n",
       "mean_dew_point                     float64\n",
       "mean_visibility                    float64\n",
       "mean_wind_speed                    float64\n",
       "max_sustained_wind_speed           float64\n",
       "max_temperature                    float64\n",
       "max_temperature_explicit           boolean\n",
       "total_precipitation                float64\n",
       "fog                                boolean\n",
       "rain                               boolean\n",
       "snow                               boolean\n",
       "hail                               boolean\n",
       "thunder                            boolean\n",
       "tornado                            boolean\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_tmp.dtypes # Check if data types match categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_tmp['day_diff'] = (df_clean_tmp.groupby('station_number')['date'].shift(-1) - df_clean_tmp['date']).dt.days # Compute the difference in days between neighbouring rows\n",
    "df_clean_tmp['target'] = df_clean_tmp.groupby('station_number')['snow'].shift(-1) # Create new target column containing information about snow from the next day\n",
    "\n",
    "# Add data from day before \n",
    "df_clean_tmp['snow_before'] = df_clean_tmp.groupby('station_number')['snow'].shift(1) \n",
    "df_clean_tmp['rain_before'] = df_clean_tmp.groupby('station_number')['rain'].shift(1)\n",
    "df_clean_tmp['mean_temp_before'] = df_clean_tmp.groupby('station_number')['mean_temp'].shift(1)\n",
    "df_clean_tmp['total_precipitation_before'] = df_clean_tmp.groupby('station_number')['total_precipitation'].shift(1)\n",
    "df_clean_tmp['mean_dew_point_before'] = df_clean_tmp.groupby('station_number')['mean_dew_point'].shift(1)\n",
    "df_clean_tmp['max_temperature_before'] = df_clean_tmp.groupby('station_number')['max_temperature'].shift(1)\n",
    "\n",
    "df_clean_tmp = df_clean_tmp[df_clean_tmp['day_diff'] == 1] # Remove data where the next day is missing\n",
    "df_clean_tmp = df_clean_tmp.dropna() # Drop NA values resulting from injecting data from previous/next days\n",
    "\n",
    "# Convert bool. columns into binary 0 and 1\n",
    "bool_cols = df_clean_tmp.select_dtypes(include='bool').columns \n",
    "df_clean_tmp[bool_cols] = df_clean_tmp[bool_cols].astype(int)\n",
    "\n",
    "\n",
    "df_clean = df_clean_tmp.copy()\n",
    "assert not df_clean.isnull().values.any(), \"DataFrame contains NaN values\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Task\n",
    "Now it is time to split the data, into a training, evaluation and test set. As a reminder, the date we are trying to predict snow fall for should constitute your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall length 21795\n",
      "Train set length 18183\n",
      "Evaluation set length 3602\n",
      "Test set length 10\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "date_to_predict = str(dt.datetime.today()- dt.timedelta(days=20*365)).split(' ')[0]\n",
    "\n",
    "# Train set contains data from 2000 until 2004\n",
    "train_df = df_clean[df_clean['date'] <= '2004-12-31']\n",
    "\n",
    "# Evaluation set contains data from 2004 until 2005 except for \"date_to_predict\"\n",
    "eval_df = df_clean[(df_clean['date'] > '2004-12-31') & (df_clean['date'] != date_to_predict)]\n",
    "\n",
    "# Test set contains data with the same date as \"date_to_predict\"\n",
    "test_df = df_clean[(df_clean['date'] == date_to_predict)]\n",
    "\n",
    "print(f\"Overall length {len(df_clean)}\")\n",
    "print(f\"Train set length {len(train_df)}\")\n",
    "print(f\"Evaluation set length {len(eval_df)}\")\n",
    "print(f\"Test set length {len(test_df)}\")\n",
    "\n",
    "assert len(df_clean) == len(train_df) + len(eval_df) + len(test_df), \"The lengths of the train, evaluation, and test sets do not sum to the length of the whole dataset\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "If you made it up to here all by yourself, you can use your prepared dataset to train an algorithm of your choice to forecast whether it will snow on the following date for each station in this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2005-05-12'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "str(dt.datetime.today()- dt.timedelta(days=20*365)).split(' ')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are allowed to use any library you are comfortable with such as sklearn, tensorflow, keras etc. \n",
    "If you did not manage to finish part one feel free to use the data provided in 'coding_challenge.csv' Note that this data does not represent a solution to Part 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choose which columns to use for the model \n",
    "predictors=['mean_temp', 'mean_dew_point',\n",
    "       'mean_visibility', 'mean_wind_speed',\n",
    "       'max_temperature', 'total_precipitation',\n",
    "       'fog', 'rain', 'snow', 'hail', 'mean_temp_before', 'total_precipitation_before', 'snow_before', 'rain_before']\n",
    "\n",
    "# Choose columns to normalize\n",
    "columns_to_scale = ['mean_temp', 'mean_dew_point',\n",
    "       'mean_visibility', 'mean_wind_speed',\n",
    "       'max_temperature', 'total_precipitation',\n",
    "       'mean_temp_before', 'total_precipitation_before']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numeric columns\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(train_df[columns_to_scale])\n",
    "X_eval_scaled = scaler.transform(eval_df[columns_to_scale])\n",
    "X_test_scaled = scaler.transform(test_df[columns_to_scale])\n",
    "\n",
    "train_df.loc[:, columns_to_scale] = X_train_scaled\n",
    "eval_df.loc[:, columns_to_scale] = X_eval_scaled\n",
    "test_df.loc[:, columns_to_scale] = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(class_weight={0: 1, 1: 3}, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(class_weight={0: 1, 1: 3}, kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(class_weight={0: 1, 1: 3}, kernel='linear')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train model\n",
    "class_weights = {0: 1, 1: 3} # Add class weights due to unbalanced dataset\n",
    "model = SVC(kernel='linear', class_weight=class_weights)\n",
    "model.fit(train_df[predictors], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5311355311355311\n",
      "Confusion Matrix:\n",
      "[[2399  385]\n",
      " [ 383  435]]\n"
     ]
    }
   ],
   "source": [
    "eval_predictions = model.predict(eval_df[predictors]) # Evaluate the model\n",
    "print(f\"F1 Score: {f1_score(eval_df['target'], eval_predictions)}\") # Compute F1 score\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(eval_df['target'], eval_predictions)}\") # Compute confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for day after: 2005-05-12\n",
      "At station number 725300 predicted snowfall False - correct prediction False\n",
      "At station number 725305 predicted snowfall False - correct prediction False\n",
      "At station number 725314 predicted snowfall False - correct prediction False\n",
      "At station number 725315 predicted snowfall False - correct prediction False\n",
      "At station number 725316 predicted snowfall False - correct prediction False\n",
      "At station number 725317 predicted snowfall False - correct prediction False\n",
      "At station number 725320 predicted snowfall False - correct prediction True\n",
      "At station number 725326 predicted snowfall False - correct prediction False\n",
      "At station number 725327 predicted snowfall False - correct prediction False\n",
      "At station number 725330 predicted snowfall True - correct prediction False\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(test_df[predictors]) # evaluate test data\n",
    "print(f\"Predictions for day after: {date_to_predict}\")\n",
    "for prediction_idx, (row_idx, row) in enumerate(test_df.iterrows()):\n",
    "    print(f\"At station number {row['station_number']} predicted snowfall {bool(test_predictions[prediction_idx])} - correct prediction {bool(row['target'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "7l_datascience",
   "language": "python",
   "name": "7l_datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
